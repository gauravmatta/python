{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "#At input Layer perform the preprocessing,we fine tune data, we remove anamolies\n",
    "#As the data is fed it jumps from layer after layer as it is a feed forward network\n",
    "#Batch normalization helps in normalizing that layer as it passes data.\n",
    "#It considers the weight in activation functions,it understands the mean and standard deviation,figures out the anamolies if any so the data is in reasonable range and outliners are avoided.\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "#Tensorboard is used to Visualize our Neural Network, acts as a GUI to visualize the whole network epoch by epoch or run by run\n",
    "#It helps to come to conclusions like by what extent the network is learning and how accuracy is trending, is it becoming flat at a particualar epoch.\n",
    "#TensorBoard creates a model log for each epoch\n",
    "#TensorBoard creates a url link to visualize TensorBoard\n",
    "from keras.callbacks import TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tflearn.datasets.oxflower17 as oxflower17\n",
    "#When output is more than 2 we use softmax and softmax is Probablity Distribution\n",
    "#For Decision Making these probabilities need to be converted into final output\n",
    "#We do it using function orgMax in python go through the probabilities in SoftMax and pick up the highest probability\n",
    "#We then return that as perdiction by the Model.\n",
    "#When we use one_hot=true the system takes probability distributions out example 0-9 and returns the digit with highest probability\n",
    "#In oxford Flower dataset we have multiple categories and each category has 17 images so we are using it here.\n",
    "X,Y = oxflower17.load_data(one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# No of neurons is also called as Kernel\n",
    "# Kernel size picks up a particular zone and captures key features of image from that zone\n",
    "# Stride is the degree at which we should move to next kernel i.e. after how many pixels we will get next kernel\n",
    "model.add(Conv2D(96,kernel_size=(11,11), strides=(4,4), activation='relu',input_shape=(224,224,3)))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "#Intially we have key features as we move we get more refined key features so we can focus on more neurons\n",
    "#So images will be much sharper\n",
    "#Input shape is only added to the input layer\n",
    "model.add(Conv2D(256,kernel_size=(5,5),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(256,kernel_size=(3,3),activation='relu'))\n",
    "model.add(Conv2D(384,kernel_size=(3,3),activation='relu'))\n",
    "model.add(Conv2D(256,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096,activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096,activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(17,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 54, 54, 96)        34944     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 26, 26, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 26, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 22, 256)       614656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 10, 10, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 6, 384)         885120    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 256)         884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1, 1, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 17)                69649     \n",
      "=================================================================\n",
      "Total params: 20,915,857\n",
      "Trainable params: 20,914,641\n",
      "Non-trainable params: 1,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorbrd = TensorBoard('logs/gaurav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1224 samples, validate on 136 samples\n",
      "Epoch 1/5\n",
      "1224/1224 [==============================] - 198s 162ms/step - loss: 4.8337 - acc: 0.1658 - val_loss: 9.4382 - val_acc: 0.1250\n",
      "Epoch 2/5\n",
      "1224/1224 [==============================] - 278s 227ms/step - loss: 4.3807 - acc: 0.2377 - val_loss: 6.1153 - val_acc: 0.0735\n",
      "Epoch 3/5\n",
      "1224/1224 [==============================] - 264s 216ms/step - loss: 3.0194 - acc: 0.2614 - val_loss: 3.4066 - val_acc: 0.2206\n",
      "Epoch 4/5\n",
      "1224/1224 [==============================] - 201s 164ms/step - loss: 2.6353 - acc: 0.2990 - val_loss: 2.6540 - val_acc: 0.3382\n",
      "Epoch 5/5\n",
      "1224/1224 [==============================] - 213s 174ms/step - loss: 2.5360 - acc: 0.2892 - val_loss: 3.3525 - val_acc: 0.2353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21ac04c4278>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y,batch_size=64,epochs=5,verbose=1,validation_split=0.1,shuffle=True,callbacks=[tensorbrd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
